{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90b3f8eb",
   "metadata": {},
   "source": [
    "**Objective:** Load the excel file containing the TMA cores information and sort the patient, samples and annotations for renaming the QuPath's images export/output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c4ffa4",
   "metadata": {},
   "source": [
    "# 1.0 Get the excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "bbfaff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "2d03cd8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TMA 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kontroll</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kontroll</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NT</td>\n",
       "      <td>MC</td>\n",
       "      <td>MC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FC</td>\n",
       "      <td>FC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FC</td>\n",
       "      <td>PC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lgl 457</td>\n",
       "      <td>463</td>\n",
       "      <td>468</td>\n",
       "      <td>475</td>\n",
       "      <td>482</td>\n",
       "      <td>487</td>\n",
       "      <td>493</td>\n",
       "      <td>499</td>\n",
       "      <td>505</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lgl 457</td>\n",
       "      <td>463</td>\n",
       "      <td>468</td>\n",
       "      <td>475</td>\n",
       "      <td>482</td>\n",
       "      <td>487</td>\n",
       "      <td>493</td>\n",
       "      <td>499</td>\n",
       "      <td>505</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0        1    2         3    4         5    6    7    8    9    10\n",
       "0    TMA 1      NaN  NaN  kontroll  NaN  kontroll  NaN  NaN  NaN  NaN  NaN\n",
       "1      NaN        1    7        12   18        23   28   33   39   43   48\n",
       "2      NaN       NT   MC        MC  NaN       NaN   FC   FC  NaN  NaN   PC\n",
       "3      NaN        1    7        12   18        23   28   33   39   43   48\n",
       "4      NaN       MC  NaN        MC  NaN       NaN   FC  NaN   PC  NaN   PC\n",
       "..     ...      ...  ...       ...  ...       ...  ...  ...  ...  ...  ...\n",
       "228    NaN      NaN   FC        PC  NaN       NaN  NaN   FC  NaN  NaN   MC\n",
       "229    NaN  lgl 457  463       468  475       482  487  493  499  505  512\n",
       "230    NaN      NaN  NaN       NaN   PC       NaN   PC  NaN  NaN   MC  NaN\n",
       "231    NaN  lgl 457  463       468  475       482  487  493  499  505  512\n",
       "232    NaN      NaN  NaN       NaN   FC       NaN  NaN  NaN  NaN   PC   PC\n",
       "\n",
       "[233 rows x 11 columns]"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the excel file\n",
    "FILE_PATH = 'C:/Users/tariq/GDrive (m.rifqi901)/SCIN/PHD/tasks/tma_analysis/Consecutive Cohort Core Analysis _2.xlsx'\n",
    "df = pd.read_excel(FILE_PATH, header=None)\n",
    "#df = df.drop([11,12,13,14,15], axis=1)\n",
    "df = df.loc[:,0:10]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "e95fb709",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['TMA1', 0],\n",
       " ['TMA2', 26],\n",
       " ['TMA3', 52],\n",
       " ['TMA4', 78],\n",
       " ['TMA5', 104],\n",
       " ['TMA6', 130],\n",
       " ['TMA7', 156],\n",
       " ['TMA8', 182],\n",
       " ['TMA9', 208]]"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get index where to seperate the TMAs\n",
    "tma_loc = df.index[df[0].str.contains(\"TMA\", case=False)==True].tolist()\n",
    "\n",
    "# create a list of TMAs with its index locations\n",
    "tma_list = []\n",
    "for i in tma_loc:\n",
    "    x = df.iloc[i,0]\n",
    "    x = x.replace(\" \", \"\")\n",
    "    x = [x, i]\n",
    "    tma_list.append(x)\n",
    "    #print(x)\n",
    "tma_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee6a34a",
   "metadata": {},
   "source": [
    "# 2.0 Load helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a191256",
   "metadata": {},
   "source": [
    "Helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "3c5e07ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def CreateDfs(tma_loc=[], sort=True, save=True, *args):\n",
    "    '''\n",
    "    Functions:\n",
    "    Read the excel files that contain the TMAs information\n",
    "    and convert that into dataframes for processing.\n",
    "    The output will be processed dataframe with annotated names\n",
    "    and textfile that contains filenames for renamer function.\n",
    "    \n",
    "    Arguments:\n",
    "    tma_loc (list) = expect TMA# and location index ie: ['TMA1', 0]\n",
    "    sort (bool) = wheter to sort dataframe according to patients or positional index\n",
    "    save (bool) = save dataframes as csv and filenames as .txt\n",
    "    \n",
    "    '''\n",
    "    # select the arrays\n",
    "    df_tma = df[tma_loc[1]:(tma_loc[1]+25)]\n",
    "    df_tma = df_tma.iloc[:,1:11]\n",
    "    \n",
    "    # replace NaN with 0\n",
    "    df_tma = df_tma.fillna(0)\n",
    "    \n",
    "    # add new row\n",
    "    new_row = [0,0,0,0,0,0,0,0,0,0]\n",
    "    new_row = pd.Series(new_row, index=df_tma.columns)\n",
    "    df_tma = pd.concat([df_tma.iloc[:1], new_row.to_frame().T, df_tma.iloc[1:]], ignore_index = True)\n",
    "    \n",
    "    # select even rows (patients)\n",
    "    df_tma_e = df_tma[::2]\n",
    "\n",
    "    # select odd rows (annotations)\n",
    "    df_tma_o = df_tma[1::2]\n",
    "\n",
    "    ##_____stacking patients_____\n",
    "    \n",
    "    # create an empty df to list all\n",
    "    df_list = pd.DataFrame()\n",
    "\n",
    "    # concat each columns into one column\n",
    "    for i in df_tma_e.columns.tolist():\n",
    "        ii = i-1\n",
    "        x = df_tma_e.iloc[:,ii]\n",
    "        df_list = pd.concat([df_list, x], ignore_index=True)\n",
    "        #print(f\"stacking column: {ii}\")\n",
    "\n",
    "    # import for sort\n",
    "    from natsort import index_natsorted\n",
    "    import numpy as np\n",
    "\n",
    "    # sort the list\n",
    "    df_list.columns = [\"patients\"]\n",
    "    df_list = df_list.astype(str)\n",
    "    df_list.sort_values(by='patients', key=lambda x: np.argsort(index_natsorted(df_list[\"patients\"])))\n",
    "    df_list = df_list.reset_index(inplace=False)\n",
    "    df_list = df_list.drop(\"index\", axis=1)\n",
    "    \n",
    "    ##_____stacking samples_____\n",
    "    \n",
    "    # create an empty df to list all\n",
    "    df_samples = pd.DataFrame()\n",
    "\n",
    "    # concat each columns into one column\n",
    "    for i in df_tma_o.columns.tolist():\n",
    "        ii = i-1\n",
    "        x = df_tma_o.iloc[:,ii]\n",
    "        df_samples = pd.concat([df_samples, x], ignore_index=True)\n",
    "        #print(f\"stacking column: {ii}\")\n",
    "\n",
    "    # import for sort\n",
    "    #from natsort import index_natsorted\n",
    "    #import numpy as np\n",
    "\n",
    "    # sort the list\n",
    "    df_samples.columns = [\"samples\"]\n",
    "    df_samples = df_samples.astype(str)\n",
    "    df_samples.sort_values(by='samples', key=lambda x: np.argsort(index_natsorted(df_samples[\"samples\"])))\n",
    "    df_samples = df_samples.reset_index(inplace=False)\n",
    "    df_samples = df_samples.drop(\"index\", axis=1)\n",
    "    \n",
    "    df_list = pd.merge(df_list, df_samples,left_index=True, right_index=True)\n",
    "    df_list.reset_index(inplace=True)\n",
    "    \n",
    "    ##_____annotating the data_____\n",
    "    \n",
    "    # count how many samples per patients\n",
    "    df_uniq = df_list['patients'].value_counts()\n",
    "    patients = df_uniq.index.tolist()\n",
    "    samples = df_uniq.values.tolist()\n",
    "    dict = {'patients':patients, 'samples':samples}\n",
    "    df_uniq = pd.DataFrame(dict, columns=[\"patients\", \"samples\"])\n",
    "    \n",
    "    # create annonated pat_sam (patients_samples)\n",
    "    df_pat_sam = pd.DataFrame()\n",
    "    for i in df_uniq.index.tolist():\n",
    "        ii = df_uniq.iloc[i,0]\n",
    "        iii = df_uniq.iloc[i,1]\n",
    "\n",
    "        for x in range(iii):\n",
    "            xx = x + 1\n",
    "            xxx = [ii, str(ii) + \"_\" + str(xx)]\n",
    "            xxx = pd.Series(xxx)\n",
    "            #print(xxx)\n",
    "            df_pat_sam = pd.concat([df_pat_sam, xxx], axis=1, ignore_index=True)\n",
    "\n",
    "    df_pat_sam = df_pat_sam.T\n",
    "    df_pat_sam = df_pat_sam.rename(columns = {0:'index', 1:'pat_sam'})\n",
    "    \n",
    "    # use natsorted for consistent sorting\n",
    "    #from natsort import natsorted\n",
    "    pat_sam = df_pat_sam.values.tolist()\n",
    "    pat_sam = natsorted(pat_sam, key = lambda x: x[1])\n",
    "    all = df_list.values.tolist()\n",
    "    all = natsorted(all, key = lambda x: x[1])\n",
    "    \n",
    "    ##_____final annotations of the data_____\n",
    "        \n",
    "    df_all = pd.DataFrame()\n",
    "    ii = -1\n",
    "    annot = []\n",
    "\n",
    "    for i in pat_sam:\n",
    "        ii += 1\n",
    "        x = [i, all[ii]]\n",
    "        x = sum(x, [])\n",
    "        #print(x[4])\n",
    "\n",
    "        if x[4] == '0':\n",
    "            annot = [str(tma_loc[0]) + '_' + str(x[1])]\n",
    "            xx = [x, annot]\n",
    "            xx = sum(xx, [])\n",
    "            #print(xx)\n",
    "        else:\n",
    "            annot = [str(tma_loc[0]) + '_' + str(x[1]) + '_' + str(x[4])]\n",
    "            xx = [x, annot]\n",
    "            xx = sum(xx, [])\n",
    "            #print(xx)\n",
    "\n",
    "        xx = pd.Series(xx)\n",
    "        df_all = pd.concat([df_all, xx], axis=1, ignore_index=True)\n",
    "\n",
    "    df_all = df_all.T\n",
    "    col_names = {\n",
    "        0:'patients',\n",
    "        1:'pat_sam',\n",
    "        2:'positions',\n",
    "        3:'patients II',\n",
    "        4:'annotations',\n",
    "        5:'annotated'\n",
    "    }\n",
    "    df_all = df_all.rename(columns = col_names)\n",
    "\n",
    "    ##_____conditions of 'sort'_____\n",
    "        \n",
    "    if sort == True:\n",
    "        df_all = df_all.sort_values(by='positions')\n",
    "        print('Data is sorted by positions.')\n",
    "    else:\n",
    "        df_all = df_all\n",
    "        print('Data is sorted by patients (default).')\n",
    "    \n",
    "    ##_____conditions of 'save'_____\n",
    "    \n",
    "    if save == True:\n",
    "        \n",
    "        # save as csv\n",
    "        filename = str(tma_loc[0]) + \".csv\"\n",
    "        df_all.to_csv(filename, index=True)\n",
    "        print(f'Data is save as {filename}')\n",
    "        \n",
    "        # rearrange list according TMA's export\n",
    "        list_final = df_all['annotated'].tolist()\n",
    "        chunk_size = 13\n",
    "        chunked_list = list()\n",
    "\n",
    "        for i in reversed(range(0, len(list_final), chunk_size)):\n",
    "            chunked_list.append(list_final[i:i+chunk_size])\n",
    "\n",
    "        list_final = list()\n",
    "        for i in chunked_list:\n",
    "            list_final = list_final + i\n",
    "        \n",
    "        # save annotated list as text file\n",
    "        filename_txt = str(tma_loc[0]) + \".txt\"\n",
    "        text_file = open(filename_txt, 'w')\n",
    "        for i in list_final:\n",
    "            text_file.write(i + '\\n')\n",
    "        text_file.close()\n",
    "        print(f'Annotated list is save as {filename_txt}')\n",
    "    \n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "df21989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def renamer(path, textfile, imgtype='.png'):\n",
    "    '''\n",
    "    Functions:\n",
    "    Rename the core images exported by QuPath \n",
    "    using the produced textfile (created from CreateDf function)\n",
    "    as a reference.\n",
    "    \n",
    "    Arguments:\n",
    "    path (str) = directory that contains both TMA core images and the text file\n",
    "    textfile (str) = the textfile name with .txt\n",
    "    imgtype (str) = the TMA core images type\n",
    "    \n",
    "    '''\n",
    "    import os\n",
    "    os.chdir(FILE_PATH)\n",
    "    \n",
    "    ##_____get the cores_____\n",
    "    \n",
    "    # get TMA core images from the file path\n",
    "    filelist = []\n",
    "    for file in os.listdir(FILE_PATH):\n",
    "        if file.endswith(imgtype):\n",
    "            filelist.append(file)\n",
    "    filelist = natsorted(filelist)\n",
    "    #for i in filelist: print(i)\n",
    "    \n",
    "    ##_____get the filenames_____\n",
    "    \n",
    "    # get the file names from the text file\n",
    "    filenames = open(textfile, 'r')\n",
    "    filenameslines = filenames.readlines()\n",
    "    filenameslines_new = []\n",
    "    count = -1\n",
    "    for i in filenameslines:\n",
    "        count += 1\n",
    "        x = filenameslines[count].strip()\n",
    "        filenameslines_new.append(x)\n",
    "        #print(x)\n",
    "    \n",
    "    ##_____renaming the files_____\n",
    "    \n",
    "    # rename each files accordingly\n",
    "    src = []\n",
    "    for i in filelist:\n",
    "        i = os.getcwd()+'\\\\'+i\n",
    "        src.append(i)\n",
    "\n",
    "    dst = []\n",
    "    for i in filenameslines_new:\n",
    "        i = os.getcwd()+'\\\\'+i+imgtype\n",
    "        dst.append(i)\n",
    "\n",
    "    count = -1\n",
    "    for i in src:\n",
    "        count += 1\n",
    "        os.rename(i, dst[count])\n",
    "        print(f\"Renaming: {i}\\n to: {dst[count]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66902678",
   "metadata": {},
   "source": [
    "# 3.0 Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "163c31ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____Processing TMA1_____\n",
      "Data is sorted by positions.\n",
      "Data is save as TMA1.csv\n",
      "Annotated list is save as TMA1.txt\n",
      "_____Processing TMA2_____\n",
      "Data is sorted by positions.\n",
      "Data is save as TMA2.csv\n",
      "Annotated list is save as TMA2.txt\n",
      "_____Processing TMA3_____\n",
      "Data is sorted by positions.\n",
      "Data is save as TMA3.csv\n",
      "Annotated list is save as TMA3.txt\n",
      "_____Processing TMA4_____\n",
      "Data is sorted by positions.\n",
      "Data is save as TMA4.csv\n",
      "Annotated list is save as TMA4.txt\n",
      "_____Processing TMA5_____\n",
      "Data is sorted by positions.\n",
      "Data is save as TMA5.csv\n",
      "Annotated list is save as TMA5.txt\n",
      "_____Processing TMA6_____\n",
      "Data is sorted by positions.\n",
      "Data is save as TMA6.csv\n",
      "Annotated list is save as TMA6.txt\n",
      "_____Processing TMA7_____\n",
      "Data is sorted by positions.\n",
      "Data is save as TMA7.csv\n",
      "Annotated list is save as TMA7.txt\n",
      "_____Processing TMA8_____\n",
      "Data is sorted by positions.\n",
      "Data is save as TMA8.csv\n",
      "Annotated list is save as TMA8.txt\n",
      "_____Processing TMA9_____\n",
      "Data is sorted by positions.\n",
      "Data is save as TMA9.csv\n",
      "Annotated list is save as TMA9.txt\n"
     ]
    }
   ],
   "source": [
    "# get all the TMAs into list\n",
    "for i in tma_list:\n",
    "    print(f\"_____Processing {i[0]}_____\")\n",
    "    CreateDfs(i,sort=True, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5424d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renames the files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58f68ee",
   "metadata": {},
   "source": [
    "# 4.0 Etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8802761c",
   "metadata": {},
   "source": [
    "Refer https://stackoverflow.com/questions/42414968/insert-a-row-in-a-pandas-dataframe-without-changing-to-a-list-in-python to insert rows in df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd0dac1",
   "metadata": {},
   "source": [
    "Refer https://stackoverflow.com/questions/6618515/sorting-list-based-on-values-from-another-list for sorting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
